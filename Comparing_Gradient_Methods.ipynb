{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing gradient computation methods\n",
    "- Finite differences in numpy\n",
    "- Manual Backpropagation in numpy\n",
    "- Jax's value_and_grad\n",
    "- Pytorch .backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterwhidden/miniconda3/lib/python3.9/site-packages/jax/_src/lib/__init__.py:34: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create shorthand for initialing random tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 3 # 3\n",
    "\n",
    "def r(x, y=None, z=None):\n",
    "    if y is None:\n",
    "        return np.random.randn(x)\n",
    "    elif z is None:\n",
    "        return np.random.randn(x, y)\n",
    "    else:\n",
    "        return np.random.randn(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some random matrices / vectors for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array([0.2, 0.3, 0.5]) # simple arbitrary target distribution\n",
    "noise = r(ts) # random offset vector\n",
    "params = r(ts, ts) # random matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a test function which we will be computing the gradient of. It vaugely resembles a classifier with MSE loss but differs intentionally simply for the sake of working equations that haven't been used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func(ga, b, target):\n",
    "    first_p = (ga @ b)**2\n",
    "    normed = first_p / first_p.sum()\n",
    "    return ((normed - target)**2).mean()\n",
    "\n",
    "test_func_bound = lambda ga: test_func(ga, noise, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually implement jax's value_and_grad function transformation with just a few lines using finite differences. This will be extremely inefficient however when computing the gradient of a large number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_diff_value_and_grad(func):\n",
    "    def grad_f(ga):\n",
    "        eps = 0.000001\n",
    "        grad = np.zeros(ga.shape)\n",
    "        for i in range(ga.shape[0]):\n",
    "            for j in range(ga.shape[0]):\n",
    "                delta_mat = np.zeros(ga.shape)\n",
    "                delta_mat[i][j] = eps\n",
    "                bumped = ga + delta_mat\n",
    "                grad[i][j] = (func(bumped) - func(ga)) / eps\n",
    "        return grad\n",
    "    return lambda x: (func(x), grad_f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slight variation of the previous function which is even less efficient (because of reshaping in the loop) but can handle arbitrary input shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_diff_value_and_grad_v2(func):\n",
    "    def grad_f(ga):\n",
    "        eps = 0.000001\n",
    "        grad = np.zeros(ga.size)\n",
    "        bumped = ga.flatten()\n",
    "        for i in range(ga.size):\n",
    "            bumped[i] += eps\n",
    "            grad[i] = (func(bumped.reshape(ga.shape)) - func(ga)) / eps\n",
    "            bumped[i] -= eps\n",
    "        return grad.reshape(ga.shape)\n",
    "    return lambda x: (func(x), grad_f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually implement reverse-mode autodiff (backpropagation) for our function using the chain rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func_grad_backprop(a, b, target, debug=False):\n",
    "    # same calculations as test_func but broken down into individual operations\n",
    "    c = (a @ b)\n",
    "    v = c**2\n",
    "    f = v.sum()\n",
    "    h = v / f\n",
    "    k = h - target\n",
    "    m = k**2\n",
    "    n = m.sum()\n",
    "    w = n / m.shape[0]\n",
    "    \n",
    "    dw_dw = 1\n",
    "    if debug:\n",
    "        print(f'dw_dw: {dw_dw}')\n",
    "    \n",
    "    dw_dn = dw_dw * (1 / m.shape[0])\n",
    "    if debug:\n",
    "        print(f'dw_dn: {dw_dn}')\n",
    "    \n",
    "    dw_dm = dw_dn * 1\n",
    "    if debug:\n",
    "        print(f'dw_dm: {dw_dm}')\n",
    "    \n",
    "    dw_dk = dw_dm * 2 * k\n",
    "    if debug:\n",
    "        print(f'dw_dk: {dw_dk}')\n",
    "    \n",
    "    dw_dh = dw_dk * 1 # skip target\n",
    "    if debug:\n",
    "        print(f'dw_dh: {dw_dh}')\n",
    "    \n",
    "    # quotient rule, f = g(x)/h(x) -> f'(x) = g'(x)*h(x)-g(x)*h'(x) / h(x)^2\n",
    "    dw_df = (dw_dh * (-v / f**2)).sum()\n",
    "    if debug:\n",
    "        print(f'dw_df: {dw_df}')\n",
    "    \n",
    "    dw_dv = dw_df * 1 + dw_dh * (1 / f)\n",
    "    if debug:\n",
    "        print(f'dw_dv: {dw_dv}')\n",
    "\n",
    "    dw_dc = dw_dv * 2 * c \n",
    "    if debug:\n",
    "        print(f'dw_dc: {dw_dc}')\n",
    "    \n",
    "    dw_da = np.outer(dw_dc, b)\n",
    "    return w, dw_da\n",
    "\n",
    "test_func_grad_backprop_bound = lambda ga: test_func_grad_backprop(ga, noise, target)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same computation in pytorch so we can render a computation graph and compare the gradients for each variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"140pt\" height=\"601pt\"\n",
       " viewBox=\"0.00 0.00 140.00 601.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 597)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-597 136,-597 136,4 -4,4\"/>\n",
       "<!-- 5350613216 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5350613216</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 5350578784 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5350578784</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">DivBackward0</text>\n",
       "</g>\n",
       "<!-- 5350578784&#45;&gt;5350613216 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5350578784&#45;&gt;5350613216</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n",
       "</g>\n",
       "<!-- 5350579504 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5350579504</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n",
       "</g>\n",
       "<!-- 5350579504&#45;&gt;5350578784 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5350579504&#45;&gt;5350578784</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-114.8 50.5,-104.85 50.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-96.09 50.5,-86.09 47,-96.09 54,-96.09\"/>\n",
       "</g>\n",
       "<!-- 5350579696 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5350579696</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-196 6,-196 6,-177 95,-177 95,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 5350579696&#45;&gt;5350579504 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5350579696&#45;&gt;5350579504</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.75C50.5,-169.8 50.5,-159.85 50.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.09 50.5,-141.09 47,-151.09 54,-151.09\"/>\n",
       "</g>\n",
       "<!-- 5350579648 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5350579648</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-251 6,-251 6,-232 95,-232 95,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 5350579648&#45;&gt;5350579696 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5350579648&#45;&gt;5350579696</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.75C50.5,-224.8 50.5,-214.85 50.5,-206.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.09 50.5,-196.09 47,-206.09 54,-206.09\"/>\n",
       "</g>\n",
       "<!-- 5350579456 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5350579456</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-306 6,-306 6,-287 95,-287 95,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">DivBackward0</text>\n",
       "</g>\n",
       "<!-- 5350579456&#45;&gt;5350579648 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5350579456&#45;&gt;5350579648</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.75C50.5,-279.8 50.5,-269.85 50.5,-261.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.09 50.5,-251.09 47,-261.09 54,-261.09\"/>\n",
       "</g>\n",
       "<!-- 5350579360 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5350579360</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-416 6,-416 6,-397 95,-397 95,-416\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 5350579360&#45;&gt;5350579456 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5350579360&#45;&gt;5350579456</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M46.13,-396.91C41.94,-388.14 35.9,-374.01 33.5,-361 30.62,-345.39 35.89,-328 41.3,-315.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"44.6,-316.57 45.7,-306.03 38.27,-313.58 44.6,-316.57\"/>\n",
       "</g>\n",
       "<!-- 5350579408 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>5350579408</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-361 43,-361 43,-342 132,-342 132,-361\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n",
       "</g>\n",
       "<!-- 5350579360&#45;&gt;5350579408 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>5350579360&#45;&gt;5350579408</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.61,-396.75C61.78,-389.34 69.35,-378.5 75.69,-369.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.65,-371.29 81.5,-361.09 72.91,-367.29 78.65,-371.29\"/>\n",
       "</g>\n",
       "<!-- 5350579216 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>5350579216</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"92,-471 9,-471 9,-452 92,-452 92,-471\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\">MvBackward0</text>\n",
       "</g>\n",
       "<!-- 5350579216&#45;&gt;5350579360 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5350579216&#45;&gt;5350579360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-451.75C50.5,-444.8 50.5,-434.85 50.5,-426.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-426.09 50.5,-416.09 47,-426.09 54,-426.09\"/>\n",
       "</g>\n",
       "<!-- 5350579120 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5350579120</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-526 0,-526 0,-507 101,-507 101,-526\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5350579120&#45;&gt;5350579216 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5350579120&#45;&gt;5350579216</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-506.75C50.5,-499.8 50.5,-489.85 50.5,-481.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-481.09 50.5,-471.09 47,-481.09 54,-481.09\"/>\n",
       "</g>\n",
       "<!-- 5273633072 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5273633072</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-593 21,-593 21,-562 80,-562 80,-593\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-569\" font-family=\"monospace\" font-size=\"10.00\"> (3, 3)</text>\n",
       "</g>\n",
       "<!-- 5273633072&#45;&gt;5350579120 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>5273633072&#45;&gt;5350579120</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-561.92C50.5,-554.22 50.5,-544.69 50.5,-536.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-536.25 50.5,-526.25 47,-536.25 54,-536.25\"/>\n",
       "</g>\n",
       "<!-- 5350579408&#45;&gt;5350579456 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>5350579408&#45;&gt;5350579456</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81.39,-341.75C76.22,-334.34 68.65,-323.5 62.31,-314.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.09,-312.29 56.5,-306.09 59.35,-316.29 65.09,-312.29\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x13eeb5a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchviz\n",
    "\n",
    "a = torch.tensor(params)\n",
    "a.requires_grad = True\n",
    "b = torch.tensor(noise)\n",
    "targ = torch.tensor(target)\n",
    "c = (a @ b)\n",
    "c.retain_grad()\n",
    "d = c**2\n",
    "d.retain_grad()\n",
    "f = d.sum()\n",
    "f.retain_grad()\n",
    "h = d / f\n",
    "h.retain_grad()\n",
    "k = h - targ\n",
    "k.retain_grad()\n",
    "m = k**2\n",
    "m.retain_grad()\n",
    "n = m.sum()\n",
    "n.retain_grad()\n",
    "w = n / m.shape[0]\n",
    "w.retain_grad()\n",
    "w.backward()\n",
    "\n",
    "grads = {\n",
    "    'w': w.grad,\n",
    "    'n': n.grad,\n",
    "    'm': m.grad,\n",
    "    'k': k.grad,\n",
    "    'h': h.grad,\n",
    "    'f': f.grad,\n",
    "    'd': d.grad,\n",
    "    'c': c.grad,\n",
    "    'a': a.grad\n",
    "}\n",
    "\n",
    "torchviz.make_dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show gradients computed by pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: 1.0\n",
      "n: 0.3333333333333333\n",
      "m: tensor([0.3333, 0.3333, 0.3333], dtype=torch.float64)\n",
      "k: tensor([-0.0998, -0.1585,  0.2583], dtype=torch.float64)\n",
      "h: tensor([-0.0998, -0.1585,  0.2583], dtype=torch.float64)\n",
      "f: -0.19138725495718847\n",
      "d: tensor([-0.2805, -0.3329,  0.0392], dtype=torch.float64)\n",
      "c: tensor([0.1331, 0.1758, 0.0782], dtype=torch.float64)\n",
      "a: tensor([[ 0.0032,  0.0586, -0.0690],\n",
      "        [ 0.0043,  0.0774, -0.0911],\n",
      "        [ 0.0019,  0.0345, -0.0406]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for k,v in grads.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify our manually computed gradients match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_dw: 1\n",
      "dw_dn: 0.3333333333333333\n",
      "dw_dm: 0.3333333333333333\n",
      "dw_dk: [-0.09983595 -0.15849892  0.25833487]\n",
      "dw_dh: [-0.09983595 -0.15849892  0.25833487]\n",
      "dw_df: -0.19138725495718845\n",
      "dw_dv: [-0.28051157 -0.33288046  0.03923027]\n",
      "dw_dc: [0.13309974 0.17580814 0.07823145]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.07636952210140206,\n",
       " array([[ 0.00322676,  0.05861361, -0.06899421],\n",
       "        [ 0.00426215,  0.07742126, -0.09113274],\n",
       "        [ 0.00189658,  0.03445106, -0.04055242]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_func_grad_backprop(params, noise, target, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify jax's value_and_grad gives the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_auto_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_func_bound\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(ga)\u001b[0m\n\u001b[1;32m      3\u001b[0m     normed \u001b[38;5;241m=\u001b[39m first_p \u001b[38;5;241m/\u001b[39m first_p\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ((normed \u001b[38;5;241m-\u001b[39m target)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m----> 6\u001b[0m test_func_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m ga: \u001b[43mtest_auto_func\u001b[49m(ga, noise, target)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_auto_func' is not defined"
     ]
    }
   ],
   "source": [
    "jax.value_and_grad(test_func_bound)(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify both our finite difference methods also give the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finite_diff_value_and_grad(test_func_bound)(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finite_diff_value_and_grad_v2(test_func_bound)(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(params, grad_method, func):\n",
    "    weights = params.copy()\n",
    "    for i in range(1000):\n",
    "        loss, grad_val = grad_method(func)(weights)\n",
    "        weights -= 0.03 * grad_val\n",
    "        if (i % 100 == 0):\n",
    "            print(f'step {i}: loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test all of our gradient methods with the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(params, jax.value_and_grad, test_func_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "optimize(params, finite_diff_value_and_grad, test_func_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "optimize(params, finite_diff_value_and_grad_v2, test_func_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "optimize(params, lambda _: lambda p: test_func_grad_backprop(p, noise, target), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
