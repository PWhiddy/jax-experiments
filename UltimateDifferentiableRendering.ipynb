{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UltimateDifferentiableRendering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5eqICmjSYmxCnYWBfDpH/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-bounce NeRF\n",
        "What are the minimal set of assumptions about the way light interacts with a scene that we can realistically resconstruct/render basically anything? Nerf-like methods simply learn a radiance field, which works great for many things but cannot efficently take advantage of multiple bounce lighting, scattering, and pretty much all of the constraints of how photons move around in a scene. At one end of the spectrum we have categories of materials/participating media which each have tightly constrained models for how photons interact with them. Glass reflects and refracts light, diffuse and volumetric materials scatter light. If we can combine all material types into a single universal parameterizable media, and learn how the parameters vary over space, we should be able to learn more complete models of scenes more efficiently. \n",
        "We can take the primitive building block - learnable volumnes and use a slightly more sophisticated differentiable renderer. Perhaps either a path tracer or maybe photon mapping. Learnable volumes could be MLP or factored tensor volume (as in tensoRF) (x, y, z, theta, phi) -> (scatter prob, r, g, b, density/radiance/emissiveness, scattering/tranmission function params).  \n",
        "Perhaps scatter function for starters could be distribution over a few models - reflect <-> cosine distrib <-> full random scatter (this could maybe be paramed with a spread and normals), refract. \n",
        "Perhaps normal could be defined as gradient of density. \n",
        "### Description of process:\n",
        "First, take ray and for a list of steps along it compute the interaction probability (and maybe the color filtering densities?) at each step. Sample from the interaction probabilities by scanning along the interaction probabilities (optionally scan and aggregate color+densities too) and take the first where a sample threshold is reached. From here, compute full scattering function to redirect the ray (plus perhaps a small epsilon bump) as well as any color filtering. From here start back at the first step and repeat for a number of bounces. \n"
      ],
      "metadata": {
        "id": "ruKyGvyFT49y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XhzQcPDTLBU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}